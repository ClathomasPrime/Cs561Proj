\documentclass[12pt]{article}


\usepackage{wrapfig}
\usepackage{float}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,comment}
\usepackage[vlined,linesnumbered,ruled,resetcount]{algorithm2e}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\val}{val}

% \usepackage[noend]{algpseudocode}
% \usepackage{algorithm}
% \usepackage{algorithmicx}

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{conjecture}{Conjecture}

\begin{document}

% \renewcommand{\qedsymbol}{\filledbox}

\title{
  You Can't Handle the Lie: \\
  Next-Hop Verification in BGP
}
\author{
  Clay Thomas\\ claytont@cs.princeton.edu
  \and 
  Gavriel Hirsch\\ gbhirsch@cs.princeton.edu 
}
\maketitle

\begin{abstract}
  This paper presents a new protocol to be run by autonomous systems in a network alongside BGP, that reduces the set of contexts in which other AS's are incentivized to announce lies about the network. We show that by using this protocol to share control-plane information between different AS's, it is possible to detect a broader class of lies than would be possible by just doing path verification (such as in S-BGP), without having to deal with the complexity of data-plane level monitoring. We also discuss the advantages and disadvantages of this new approach, as well as the contexts in which it still does not suffice.
\end{abstract}


\section{Introduction}
Routing on the Internet involves many distinct Autonomous Systems (AS's), each with its own data sources, destinations, and links; as well as its own preferences over how traffic is routed. An AS may prefer that the traffic it sends and receives be sent over the shortest path, in order to decrease latency; or it may prefer to send its traffic through or avoiding specific other AS's for economic incentives, due to contracts between AS's about routing costs; or it may prefer to avoid certain other AS's, if it is concerned about malicious activity. In the other direction, an AS may also prefer to attract or deter traffic from certain other AS's, again for economic incentives or perhaps even to spy on certain traffic.

These AS's typically use the Border Gateway Protocol (BGP) to announce routes to neighbors and learn routes from neighbors in the control plane, and to then choose how to actually route traffic in the data plane. However, BGP does not actually enforce any requirement that an AS route traffic in a way that matches its announcements. Thus, due to all of the various (often conflicting) preferences that AS's have over how traffic is routed, these AS's can often have incentives to lie in the control plane about what they will actually do in the data plane.

We would like to be able to efficiently detect lies made by AS's in BGP announcement. However, verifying routes directly in the data plane typically involves a large overhead (CITE EXAMPLES FOR THIS, E.G. THE ONES FROM GOLDBERG). In addition, many types of lies that could be beneficial to AS's do not involve making the same lies to everyone, but rather telling distinct lies to different neighbors. As a result, if AS's are willing to collaborate then there is often information directly in the control plane that can be used to detect the existence of lies, without requiring that we monitor traffic in the data plane. In this paper we present a new protocol that we call \emph{Next-Hop Verification} which allows AS's to use this information to catch certain types of lies.

In the rest of Section 1 we discuss existing work, and we briefly outline our results and their limitations. Section 2 informally presents the model we use, and Appendix A provides a more formal model. Section 3 describes the next-hop verification protocol, and Appendices B and C contain pieces of our implementation and proofs of theorems. Section 4 describes our results and gives examples of scenarios in which next-hop verification catches lies, whereas path and loop verification are insufficient on their own. Finally, Section 5 offers some conclusions.

\subsection{Previous work}
Much work has been done on analyzing BGP through game-theoretic models in which AS's may act strategically given their incentives. \cite{RoutingGames} shows that in a general set of contexts, a form of verification called \emph{path verification}\footnote{In the original paper they refer to it as route verification.}
ensures that no group of AS's can get strictly better routes for its traffic by telling lies if everyone else is telling the truth.

However, lying can potentially give other benefits beyond getting better routes for your own traffic. As mentioned before, an AS may also have incentives to attract or deter traffic by lying. \cite{Attraction} analyzes BGP games in the presence of these types of incentives and shows that in many scenarios, even using path verification does not suffice to disincentivize lying. They also introduce another form of verification called \emph{loop verification}, which is simpler but weaker, and describe conditions under which path and loop verification do disincentivize lying. However, they admit that many of these conditions are unreasonably strong, such as requiring that AS's only consider the immediate next hop in the path in their preferences.

\subsection{Overview of our results}
As in the papers discussed above, our new \emph{next-hop verification} protocol runs in the control plane rather than in the data plane. It also allows us to catch lies even in the context where preferences involve traffic attraction and deterrence, without using path verification or relying on the strong assumptions of \cite{Attraction}. Our general analysis of next-hop verification does however use the strong assumption that there is only a single lying agent. We also for simplicity and power focus on the situation in which everyone else participates fully, though as we will discuss the protocol would still provide value even in partial deployment. In addition, next-hop verification is ``bulkier'' than loop verification, as it essentially has to distribute information across the whole collection of AS's.


\section{Model Details}
Here we present an informal description of our model for the interactions between AS's. See Appendix B for a more formalized model.

We model the network of AS's as an undirected graph, with a node for each AS and an edge between any two AS's that can directly communicate with each other without going through a third AS. We assume that the graph is a single connected component, so any AS can in theory interact with any other AS (although in practice, say if an intermediate AS intentionally drops traffic, this may not always actually be possible).

There is a unique destination AS $d$. In practice, if $N$ is the number of AS's then one could imagine having $N$ distinct versions of the problem, each of which has a different destination AS. There also may be a unique malicious AS $m$. The goal is to 

\subsection{BGP framework}
In the BGP framework, AS's can announce the existence or removal of paths to each other. Each AS has an import policy that determines how it responds to path announcements from neighboring AS's. In this paper we ignore any concerns of storage for keeping track of all announcements from neighbors, so we assume that any newly observed path is added to a table, unless the receiving AS is already in the path. In this case it will either ignore the path announcement, or if the AS never announced the subpath containing itself it will raise an alarm that another AS has exported a false path. We also assume that on hearing an announcement, the AS can only take actions related to the full path, and not related to particular subpaths.

Each AS also has an export policy which determines how it will communicate the paths it is aware of to other AS's. In some settings, such as that of (CITE GAO REXFORD) in which for example customers will not route traffic between two of their providers, an AS may prefer not to announce all of the paths it knows about to all neighbors. Relatedly, an AS may make different announcements to different neighbors.

Finally, each AS has some preferences over how the actual traffic in the network flows. As in \cite{Attraction} we assume that every AS can compile their preferences into a ranking only over paths and an export policy, both of which will be static throughout the entire game. This brings us to our notion of what it means to be honest or lie.

\begin{definition}
We say that an AS \textbf{interim lies} if it announces a path that it does not plan to use, whether that path actually exists or not, or if it fails to announce the removal of a path that it had previously announced.

We say that an AS is \textbf{interim honest} if it never lies.
\end{definition}

Note that under this definition an AS can hide information from neighbors while still being interim-honest.

\subsection{Verification}
As mentioned before, various methods of catching lies have been suggested in the literature.

\begin{definition}
In a network using \textbf{path verification} it is impossible for AS's to announce paths that include subpaths which have not already been announced to them.
\end{definition}

Some extensions to BGP, such as S-BGP, can enforce path verification. However, it requires additional overhead as well as universal adoption (CITE SOMETHING).

\begin{definition}
In a network using \textbf{loop verification} no AS will use an export policy that involves not sending a path to a neighbor specifically because that neighbor is already in the path.
\end{definition}

As mentioned before, when an AS receives a path announcement that already includes it, the AS can raise an alarm if it never announced the corresponding subpath. If instead export policies did not send paths to neighbors who are already in them, this detection could not always be done.

Since loop verification is very minimal and easy to adopt we will assume that the network uses it. We do not assume that the network uses path verification, though we will show that \emph{next-hop verification} actually handles a larger class of scenarios than path verification would.

\subsection{Convergence}
We also need to guarantee that given the rankings and export policies chosen by the AS's, BGP will converge to a stable routing graph. In the literature this is typically done via an assumption called \emph{No Dispute Wheel}, and we adopt the same assumption. See Appendix B for more details.

It is possible that some interim lies will be hard to detect. Instead, next-hop verification will focus on \emph{ex-post} honesty and lying. We often leave out the phrase ``ex-post''.

\begin{definition}
We say that an AS is \textbf{(ex-post) lying} if the stablility of the post-convergence equilibrium depends on a neighbor thinking that the AS is acting in a way that is inconsistent with the true equilibrium.

We say that an AS is \textbf{(ex-post) honest} otherwise.
\end{definition}


\section{Next-Hop Verification Protocol}
Once convergence has occurred, we propose the use of the following protocol by all of the AS's. Note that the malicious AS $m$ may lie to avoid being caught, but since convergence has already occurred we assume that none of the other AS's have an incentive to lie or even to hide information they know.

\begin{comment}
We can put all the details of the protocol implementation here

    One subtlety to note: the ASes should maybe start out by asking
    \emph{themselves} whatever next-hop queries they have. E.g. in {\sc GrandMa},
    node $a$ can immediately tell that $m$ isn't telling the truth,
    because $m$ says he forwards traffic to $a$, but doesn't.
    
\end{comment}

\section{Results/examples}
\begin{comment}
Can you add whichever theorems you think would be worth discussing in the body of the paper? We can then also add some example graphs to highlight these theorems and to contrast with path verification (either in this or a new or the previous section).
\end{comment}

\section{Conclusion}
\begin{comment}
Still need to decide what we should put here.
\end{comment}

\bibliography{proj}{}
\bibliographystyle{alpha}

\clearpage
\appendix

\section{Definition of the Game}
  We  model BGP via a two phase, asynchronous, infinite-round game,
  inspired by that of \cite{RoutingGames} and \cite{Attraction}.
  The initial data is defined by a labeled graph $G = (N,L,\mathcal V)$ which has:
  \begin{itemize}
    \item nodes $N$ representing autonomous systems
    \item edges $L \subseteq N\times N$ representing communication channels
      between the autonomous systems
    \item valuation functions $\mathcal V = \{v_i\}_{i\in N}$ for each 
      autonomous system. If $T$ represents the final state of the game,
      then $v_i(T) \in \R_{\ge 0}$.
  \end{itemize}
  Each autonomous system corresponds to an agent in the game.
  During the game, each agent $i$ keeps a tuple $(t_i, h_i, q_i)$, where
  \begin{itemize}
    % \item $t : N \to Path$ represents the forwarding table of agent $i$,
    %   satisfying the following:
    %   \begin{itemize}
    %     \item The path $t(d)$ corresponds to $i$'s \emph{believed}
    %       route to destination $d$
    %     \item If $t(d) = []$, this represents $i$ not getting a route to $d$
    %     \item If $t(d) \ne []$, then we must have $t(d).head = i$,
    %       and $t(d).last = d$
    %     \item If $t(d) \ne []$, then $t(d).nexthop$ (i.e. the first non-$i$
    %       node of $t(d)$) is the node $i$ will actually forward traffic to
    %   \end{itemize}
    \item $t_i : N \to \mathcal P (N(i))$ is the (next-hop)
      forwarding table of agent $i$, where agents are able to choose multiple
      neighbors to send traffic to\footnote{
        This allows manipulator agents to try to ``fake'' forwarding traffic
        as advertised, but actually send $99\%$ of their traffic down a different
        path.
      }
    \item $h_i$ represents the \emph{history} of agent $i$ in the game thus far.
      We treat $h$ as a sort of transcript without worrying much about its
      formal representation. In particular, $h$ keeps track of the all
      route announcements and (next-hop verification) messages received by
      agent $i$
    \item $q_i$ represents the \emph{next-hop queries} that agent $i$ has
      received. We treat $q_i$ as a queue
  \end{itemize}
  Let the set of all such tuples for agent $i$ be denote $State_i$,
  and let the set of states for all agents be denoted
  $State = \{(state_1,\ldots, state_k)\}$.

  The strategy space of each agent $i$ is given by $(imp_i, exp_i, que_i)$, where:
  \begin{itemize}
    \item $imp_i : State_i \times N \times Path^{N(i)} \to 
      \mathcal P(N(i))$ represents the 
      import policy of $i$ (for a destination $d\in N$, and paths announced by each
      neighbor $j\in N(i)$, adjust the forwarding table for destination $d$)
    \item $exp_i : State_i \times N \times N(i) \to Path$ represents
      the export policy of $i$ (for a destination $d\in N$ and neighbor $j\in N(i)$,
      what path would you announce to $j$ (if none, return an empty path))
    \item $que_i : State_i \times \mathcal P (N(i)) \times Query
      \to \{True, False\} \cup (N(i)\times Query)^*$ is the query policy
      (given that the agents $A\subseteq N(i)$ forward to you for destination
      $d$ (as given by the query), can you confirm/deny/forward the query).
  \end{itemize}

  Both phases of the game are controlled by an \emph{activator}
  that schedules agents to act\footnote{
    The activator captures the asynchronous nature of BGP.
    Previous work \cite{PolicyPathVector, RoutingGames} has gone
    even further than us and allowed message
    sending and receiving to happen in a scheduled manner,
    and allowing multiple agents to act simultaneously.
    We do not consider activation order in this level of detail.
  }. The activator must pick every agent infinitely often
  (this property is called being ``fair''),
  but other than that we assume the activator is completely adversarial,
  i.e. our positive results must hold for every fair activation sequence.
  During phase one, the activator picks an agent $i$ to act,
  and $i$ updates $t$ and $h$ from
  $state_i=(t,h,q)$ by performing the following actions
  for each $d\in N$:
  \begin{itemize}
    \item For each $j\in N(i)$, let $e(j) = exp_j(state_j, d, i)$
      denote the (possibly empty) path $j$ wants to export to $i$
      for destination $d$
    \item Update $t(d) := imp_i(state_i, d, e)$
    \item Update $h_i$ recording all observed exports and action chosen by $i$
  \end{itemize}
  The above is repeated until the following condition is reached:
  no node would change its forwarding table if activated.
  This is called reaching convergence.

  Up until now, everything in this model has been previously considered.
  We introduce phase two to capture the execution of next-hop verification,
  where nodes send around queries to try and detect lies,
  i.e. mismatches between the control and data plane.
  A query $Q(m,r,d) \in Query$ contains the following data:
  \begin{itemize}
    \item A potential manipulator $m$
    \item An announced next-hop $r$
    \item A destination $d$
  \end{itemize}
  Phase two starts after reaching convergence (formally, something)
  after which each node $i$ starts with the query $Q(m,r,d)$ for every
  destination node $d$ and every single hop $[m,r]$ on the route
  that $i$ has installed for destination $d$.
  During phase two, the activator picks a node $i$ to act,
  and $i$ updates $h$ and $q$ from $state_i=(t,h,q)$ by performing the following
  for each $query \in q$:
  \begin{itemize}
    \item If $que_i(state_i, fwds_i, query) = True$, do nothing
    \item If $que_i(state_i, fwds_i, query) = False$, then the
      ``potential manipulator'' $m$ of $query$ is ``shamed''
      and given utility $-\infty$
    \item Otherwise, $que_i(state_i, fwds_i, query) \in (N(i)\times Query)^*$
      gives a list of pairs $(j, query_j)$.
      For each such element of the list, add $query_j$ to the queue $q_j$
      of agent $j\in N(i)$.
  \end{itemize}
  Finally, update $q = []$ to the empty queue.

  At the conclusion of the game, utilities are calculated as follows:
  \begin{itemize}
    \item If convergence is not reached, all nodes receive utility $-\infty$
    \item If a node was ``shamed'' during the next-hop phase,
      it receives utility $-\infty$
    \item Otherwise, node $i$ gets utility $v_i(State)$
  \end{itemize}

\section{Definitions of Strategies and Classes of Instances}
  Let $v$ denote the valuation function of a node $i$.
  Let $T$ be the final state of a game, and let $P$ be the path
  $v$ gets to destination $d$. We assume $v$ is of the form
  $v(T) = u(P) + \alpha(T)$, where $\alpha$ is the 
  \emph{attraction function} that indicates what $i$ cares about
  other than getting a good path to $d$.
  We say that:
  \begin{itemize}
    \item $i$ is attractionless if $v(T) = u(P)$, i.e. $\alpha(T) = 0$.
    \item $i$ has volume attraction if $\alpha(T)$ is a function
      of the set of nodes whose path to $d$ includes $i$
    \item $i$ has next-hop attraction if $\alpha(T)$ is a function
      of the set of neighbors of $i$ who route directly through $i$
      as their next-hop
  \end{itemize}

  Let $strat = (imp, exp, que)$ denote the strategy profile of a node
  $i$ with valuation function $v$.
  We say that:
  \begin{itemize}
    \item $strat$ is \emph{honest} if $imp$ simply selects the highest-ranked
      path according to $v$ which is announced to $i$, and
      $exp$ only announces the current favorite
      path to the destination that node $i$ is currently using according to $imp$.
      Note that $exp$ is allowed to arbitrarily 
    \item $strat$ is a \emph{next hop participant} if $que$ implements
      next-hop verification fully and honestly, as described in
      previous sections
  \end{itemize}

  % Finally, we can formally define \emph{no incentive to lie} condition,
  % similarly to \cite{Attraction}:
  % \begin{definition}
  %   For some instance $G$ of a BGP network, there is \emph{no incentive to lie}
  %   when 
  % \end{definition}
  % We introduce the 

  Like \cite{Attraction} ((add the random lavi-nisan paper)),
  the correct ``solution concept'' for us is that of \emph{Set ex-post
  Nash equilibrium}.
  \begin{definition}
    Let $(S_1, \ldots, S_n)$ denote sets of strategies for players $1,\ldots,n$,
    i.e. each $s\in S_i$ is a function from the private information of $i$
    to a strategy.
    Then $(S_1, \ldots, S_n)$ is a \emph{Set ex-post Nash equilibrium} if
    for each player $i$ and each $\vec s _{-i} \in \vec S_{-i}$,
    there exists some $s^* \in S_i$ such that
    for \emph{all arbitrary strategies} $t$, we have
    \begin{align*}
      v_i( g_{act}( s^*(v_i), s_{-i}(v_{-i}) ) )
      \ge v_i( g_{act}( t, s_{-i}(v_{-i}) ) )
    \end{align*}
    for every set of valuations $\vec v$ and every fair activation sequence $act$.
  \end{definition}


\section{Proofs}
  ((TODO: be better))

  First, we start with a lemma that shows why next-hop verification is so
  powerful.
  \begin{lemma}
    Let $G$ be a BGP instance with the next-hop verification phase.
    Suppose all nodes except one manipulator $m$ are next-hop participants.
    Suppose that $m$ announces a next-hop of $r$ to node $n$,
    but actually uses $p\ne r$ in the data plane.
    Furthermore, suppose there exists a path from $n$ to $p$ not containing $m$.
    Then $m$ with be caught by next-hop verification, and will
    receive utility $-\infty$.
  \end{lemma}
  \begin{proof}
    The query goes along the path.
  \end{proof}

  Our first result formalizes ``when nodes are attractionless,
  there is no incentive to deviate from honest BGP with next-hop verification''.
  \begin{theorem}
    Let $G$ be an attractionless BGP instance with next-hop verification.
    Let $S = (S_1, \ldots, S_n)$ be the set of all honest, next hop participating
    strategies.
    Then $S$ is a set ex-post Nash equilibrium.
  \end{theorem}
  \begin{proof}
    If not, then every path from $victim$ to $realNextHop$ goes through $m$.
    However, this means no simple path from $m$ to $d$ can contain $victim$,
    or any of the nodes that $victim$ could directly effect without routing
    through $m$. Thus, $m$ could not have actually gotten a better path
    through the lie.
  \end{proof}

  The following theorem formalizes our claim ``nodes have no incentive
  to deviate from honest BGP when next-hop verification is used,
  even when nodes have volume attraction''.
  \begin{theorem}
    Let $G$ be a BGP instance with next-hop verification and traffic
    volume attraction.
    Let $S = (S_1, \ldots, S_n)$ be the set of all honest, next hop participating
    strategies. 
    Then $S$ is a set ex-post Nash equilibrium.
  \end{theorem}
  \begin{proof}
    As shown before, $m$ cannot get a better path. We show further
    that $m$ cannot attract more traffic (in volume).
    Suppose $m$ did manage to attract more traffic from a victim $v$.
    Then, if $P$ denotes the path $v$ originally took to $d$,
    then $P$ does not contain $m$. Because $v$ didn't use $P$
    in the honest situation, the node $n$ which $m$ lied to must
    be connected to $P$ I guess. Thus, $realNextHopOfM$
    must be connected to $d$ with a path not containing $m$,
    and $d$ is in turn connected to the guy who heard the lie.
    I guess.
  \end{proof}

  % Intuitively, if a node lies to get a better path, the node it lies
  % to and the node it routs through must be connected.
  % The following conjecture, which we hope to prove formally,
  % makes this precise.
  % \begin{conjecture}
  %   Suppose No Dispute Wheel holds, but route verification does not, and
  %   assume that the network is connected.
  %   Suppose that (assuming other nodes play truthfully)
  %   a node $m$ can achieve a better path to $d$ by announcing
  %   a route that does not exist to a node $v$.
  %   Let $m$'s next hop in the manipulated routing tree be denoted $r$.
  %   Then there exists a path in the network, not containing $m$,
  %   between $v$ and $r$.
  %   Moreover, no node along this path benefits from the manipulation
  %   performed by $m$.
  % \end{conjecture}
  % \begin{proof}
  %   For the sake of contradiction, assume that all paths between $r$
  %   and $v$ include $m$.
  %   One of $r$ or $v$ is on the ``same side of $m$'' as the destination
  %   node $d$.
  %   There must be a path from $r$ to $d$ not containing $m$,
  %   because $m$ cannot appear twice on it route to $d$ in the manipulated tree.
  %   Thus, every path from $v$ to $d$ must contain $m$.

  %   Let $T$ denote the original routing tree, and for each node $n$
  %   let $T_n$ denote the path $n$ receives to the destination.
  %   Let $M_n$ denote the advertised route that $n$ selects in the manipulated
  %   routing tree, i.e. the route $n$ believes it receives,
  %   while $\widetilde M$ is the actual manipulated routing tree and 
  %   $\widetilde M_n$ is the actual route $n$'s traffic follows.
  %   Note that the path $M_n$ need not actually exist in the graph.
  % \end{proof}

  % This means that, if all nodes other than $m$ are fully collaborative and
  % honest, the nodes will be able to detect $m$'s lie
  % by communicating along the links that already exist in the network.

\end{document}
